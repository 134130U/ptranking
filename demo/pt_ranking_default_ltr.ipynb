{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing learning-to-rank with default setting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the evaluation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from org.archive.ltr_adhoc.eval.l2r import L2REvaluator\n",
    "\n",
    "# Required input and output directories\n",
    "data_id = 'MQ2007_Super'\n",
    "dir_data = '/Users/dryuhaitao/WorkBench/Corpus/LETOR4.0/MQ2007/'\n",
    "dir_output='/Users/dryuhaitao/WorkBench/output/'\n",
    "\n",
    "evaluator = L2REvaluator()\n",
    "\n",
    "data_dict, eval_dict = evaluator.get_default_dicts(data_id=data_id, dir_data=dir_data, dir_output=dir_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold- 1\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, vali_data = evaluator.load_data(eval_dict=eval_dict, data_dict=data_dict, fold_k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of the neural scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sf_para_dict = evaluator.get_default_sf_para_dict(data_dict=data_dict, eval_dict=eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The specified model with default parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'RankNet'\n",
    "model_para_dict = evaluator.get_default_para_dict(model_id=model_id)\n",
    "# required basic check before loading the ranker\n",
    "evaluator.setup_eval(data_dict=data_dict, eval_dict=eval_dict, sf_para_dict=sf_para_dict, model_para_dict=model_para_dict)\n",
    "\n",
    "ranker   = evaluator.load_ranker(data_dict=data_dict, eval_dict=eval_dict, model_para_dict=model_para_dict, sf_para_dict=sf_para_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_var(list_vals, lbl=None):\n",
    "    X = np.arange(start=1, stop=len(list_vals)+1).tolist()\n",
    "    if lbl is not None:\n",
    "        plt.plot(X, list_vals, label=lbl)\n",
    "    else:\n",
    "        plt.plot(X, list_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the learning-to-rank model and plot the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-309f5c49c52c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mranknet_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mranknet_train_ndcgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mranknet_test_ndcgs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbasic_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mranker\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mranker\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meval_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0meval_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mshow_var\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mranknet_losses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlbl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Training loss'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# show the variation of loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlegend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'RankNet'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/WorkBench/Dropbox/CodeBench/Cosmos/PycharmProjects/public-ptl2r/org/archive/ltr_adhoc/eval/l2r.py\u001B[0m in \u001B[0;36mbasic_train\u001B[0;34m(self, ranker, eval_dict, train_data, test_data, vali_data)\u001B[0m\n\u001B[1;32m    565\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mqid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_rankings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_stds\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    566\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgpu\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbatch_rankings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_stds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch_rankings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_stds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 567\u001B[0;31m                 \u001B[0mbatch_loss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_training\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mranker\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_rankings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_stds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mqid\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mqid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    568\u001B[0m                 \u001B[0mepoch_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mbatch_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/WorkBench/Dropbox/CodeBench/Cosmos/PycharmProjects/public-ptl2r/org/archive/base/ranker.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, batch_ranking, batch_label, **kwargs)\u001B[0m\n\u001B[1;32m    180\u001B[0m             \u001B[0mstop_training\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstop_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 182\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minner_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_pred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_training\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    183\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/WorkBench/Dropbox/CodeBench/Cosmos/PycharmProjects/public-ptl2r/org/archive/ltr_adhoc/pairwise/ranknet.py\u001B[0m in \u001B[0;36minner_train\u001B[0;34m(self, batch_pred, batch_label, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0mbatch_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mbatch_loss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch11/lib/python3.7/site-packages/torch/optim/adam.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m     62\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m                     \u001B[0;32mcontinue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 64\u001B[0;31m                 \u001B[0mgrad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     65\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgrad\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_sparse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m                     \u001B[0;32mraise\u001B[0m \u001B[0mRuntimeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Adam does not support sparse gradients, please consider SparseAdam instead'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ranknet_losses, ranknet_train_ndcgs, ranknet_test_ndcgs = evaluator.basic_train(ranker=ranker, eval_dict=eval_dict, train_data=train_data, test_data=test_data)\n",
    "\n",
    "show_var(ranknet_losses, lbl='Training loss') # show the variation of loss\n",
    "plt.legend()\n",
    "plt.title('RankNet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (ptl2r)",
   "language": "python",
   "name": "pycharm-a6d7dfad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}