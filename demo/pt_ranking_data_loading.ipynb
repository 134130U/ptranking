{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check the statistics of a specified dataset with default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from org.archive.data.data_utils import L2RDataset, YAHOO_L2R, ISTELLA_L2R\n",
    "\n",
    "def get_doc_num(dataset):\n",
    "    '''\n",
    "    Get the number of documents\n",
    "    '''\n",
    "    doc_num = 0\n",
    "    for qid, torch_batch_rankings, torch_batch_std_labels in dataset:\n",
    "        doc_num += torch_batch_std_labels.size(1)\n",
    "\n",
    "    return doc_num\n",
    "\n",
    "def get_min_max_docs(train_dataset, vali_dataset, test_dataset):\n",
    "    '''\n",
    "    Get the maximum/minimum w.r.t. documents per query\n",
    "    '''\n",
    "    min_doc = 10000000\n",
    "    max_doc = 0\n",
    "    sum_rele = 0\n",
    "\n",
    "    for qid, torch_batch_rankings, torch_batch_std_labels in train_dataset:\n",
    "        #print('torch_batch_std_labels', torch_batch_std_labels.size())\n",
    "        doc_num = torch_batch_std_labels.size(1)\n",
    "        min_doc = min(doc_num, min_doc)\n",
    "        max_doc = max(max_doc, doc_num)\n",
    "        sum_rele += (torch_batch_std_labels>0).sum()\n",
    "\n",
    "    for qid, torch_batch_rankings, torch_batch_std_labels in vali_dataset:\n",
    "        doc_num = torch_batch_std_labels.size(1)\n",
    "        min_doc = min(doc_num, min_doc)\n",
    "        max_doc = max(max_doc, doc_num)\n",
    "        sum_rele += (torch_batch_std_labels>0).sum()\n",
    "\n",
    "    for qid, torch_batch_rankings, torch_batch_std_labels in test_dataset:\n",
    "        doc_num = torch_batch_std_labels.size(1)\n",
    "        min_doc = min(doc_num, min_doc)\n",
    "        max_doc = max(max_doc, doc_num)\n",
    "        sum_rele += (torch_batch_std_labels>0).sum()\n",
    "\n",
    "    return min_doc, max_doc, sum_rele.data.numpy()\n",
    "\n",
    "\n",
    "def get_dataset_statistics(data_id, dir_data, buffer=False):\n",
    "    '''\n",
    "    Get the basic statistics on the specified dataset\n",
    "    :param data_id: the dataset ID\n",
    "    :param dir_data: the directory of the dataset\n",
    "    :param buffer: if true, it will buffer the data in the format of numpy-tensor and pytorch-tensor\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    if data_id in YAHOO_L2R:\n",
    "        data_prefix = dir_data + data_id.lower() + '.'\n",
    "        file_train, file_vali, file_test = data_prefix + 'train.txt', data_prefix + 'valid.txt', data_prefix + 'test.txt'\n",
    "\n",
    "    elif data_id in ISTELLA_L2R:\n",
    "        data_prefix = dir_data + data_id + '/'\n",
    "\n",
    "        if data_id == 'Istella_X' or data_id=='Istella_S':\n",
    "            file_train, file_vali, file_test = data_prefix + 'train.txt', data_prefix + 'vali.txt', data_prefix + 'test.txt'\n",
    "        else:\n",
    "            file_train, file_test = data_prefix + 'train.txt', data_prefix + 'test.txt'\n",
    "\n",
    "    else:\n",
    "        fold_k = 1\n",
    "        fold_k_dir = dir_data + 'Fold' + str(fold_k) + '/'\n",
    "        file_train, file_vali, file_test = fold_k_dir + 'train.txt', fold_k_dir + 'vali.txt', fold_k_dir + 'test.txt'\n",
    "\n",
    "    # common\n",
    "    if 'Istella' == data_id:\n",
    "        pass # since there is no vali part\n",
    "    else:\n",
    "        train_dataset = L2RDataset(train=True, file=file_train, data_id=data_id, shuffle=False, buffer=buffer)\n",
    "        vali_dataset =  L2RDataset(train=False, file=file_vali, data_id=data_id, shuffle=False, buffer=buffer)\n",
    "        test_dataset =  L2RDataset(train=False, file=file_test, data_id=data_id, shuffle=False, buffer=buffer)\n",
    "\n",
    "        num_queries = train_dataset.__len__() + vali_dataset.__len__() + test_dataset.__len__()\n",
    "        print('Dataset:\\t', data_id)\n",
    "        print('Total queries:\\t', num_queries)\n",
    "        print('\\tTrain:', train_dataset.__len__(), 'Vali:', vali_dataset.__len__(), 'Test:', test_dataset.__len__())\n",
    "\n",
    "        num_docs = get_doc_num(train_dataset) + get_doc_num(vali_dataset) + get_doc_num(test_dataset)\n",
    "        print('Total docs:\\t', num_docs)\n",
    "\n",
    "        min_doc, max_doc, sum_rele = get_min_max_docs(train_dataset=train_dataset, vali_dataset=vali_dataset, test_dataset=test_dataset)\n",
    "        print('min, max documents per query', min_doc, max_doc)\n",
    "        print('total relevant documents', sum_rele)\n",
    "        print('avg rele documents per query', sum_rele * 1.0 / num_queries)\n",
    "        print('avg documents per query', num_docs * 1.0 / num_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the statistics of a specified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\t MQ2007_Super\n",
      "Total queries:\t 1692\n",
      "\tTrain: 1017 Vali: 339 Test: 336\n",
      "Total docs:\t 69623\n",
      "min, max documents per query 6 147\n",
      "total relevant documents 17991\n",
      "avg rele documents per query 10.632978723404255\n",
      "avg documents per query 41.1483451536643\n"
     ]
    }
   ],
   "source": [
    "# The basic information that needs to be specified\n",
    "data_id  = 'MQ2007_Super'\n",
    "dir_data = '/Users/dryuhaitao/WorkBench/Corpus/LETOR4.0/MQ2007/'\n",
    "buffer   = False\n",
    "get_dataset_statistics(data_id=data_id, dir_data=dir_data, buffer=buffer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a6d7dfad",
   "language": "python",
   "display_name": "PyCharm (ptl2r)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}